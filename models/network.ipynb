{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Defined Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Includes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# mass includes\n",
    "import torch as t\n",
    "import numpy as np\n",
    "from ipynb.fs.full.module import BasicModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Encoder(BasicModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.model_name = 'Encoder'\n",
    "\n",
    "        # feature extraction convnet\n",
    "        self.feats = t.nn.Sequential(\n",
    "            t.nn.Conv2d(3, 32, 3, padding=1, bias=False), t.nn.BatchNorm2d(32),\n",
    "            t.nn.ReLU(), t.nn.MaxPool2d(2),\n",
    "            t.nn.Conv2d(32, 64, 3, padding=1, bias=False),\n",
    "            t.nn.BatchNorm2d(64), t.nn.ReLU(), t.nn.MaxPool2d(2),\n",
    "            t.nn.Conv2d(64, 128, 3, padding=1, bias=False),\n",
    "            t.nn.BatchNorm2d(128), t.nn.ReLU(), t.nn.MaxPool2d(2),\n",
    "            t.nn.Conv2d(128, 256, 3, padding=1, bias=False),\n",
    "            t.nn.BatchNorm2d(256), t.nn.ReLU(),\n",
    "            t.nn.Conv2d(256, 256, 3, padding=1, bias=False))\n",
    "\n",
    "        # for pooling binary mask\n",
    "        self.mpool = t.nn.MaxPool2d(2**3)\n",
    "\n",
    "    def forward(self, in_img, in_mask):\n",
    "        out_feats = self.feats(in_img)\n",
    "        out_mask = self.mpool(in_mask)\n",
    "\n",
    "        return out_feats, out_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature summary network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Summarizer(BasicModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Summarizer, self).__init__()\n",
    "        self.model_name = 'Summarizer'\n",
    "\n",
    "        # feature sunmmation\n",
    "        self.feats = t.nn.Sequential(\n",
    "            t.nn.Conv2d(256, 512, 3, padding=1, bias=False),\n",
    "            t.nn.BatchNorm2d(512), t.nn.ReLU(), t.nn.MaxPool2d(8),\n",
    "            t.nn.Flatten(), t.nn.Linear(512 * 2 * 2, 256, bias=False),\n",
    "            t.nn.BatchNorm1d(256), t.nn.ReLU(),\n",
    "            t.nn.Linear(256, 128, bias=False))\n",
    "\n",
    "    def forward(self, in_feats, in_mask):\n",
    "        out_feats = self.feats(in_feats)\n",
    "\n",
    "        return out_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual infomstion discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class MIDiscriminator(BasicModule):\n",
    "\n",
    "    def __init__(self, loc_chnls=256, glb_chnls=128, out_chnls=2048):\n",
    "        super(MIDiscriminator, self).__init__()\n",
    "        self.model_name = 'Disc-mi'\n",
    "\n",
    "        # from table 8\n",
    "        self.glb_feats1 = t.nn.Sequential(\n",
    "            t.nn.Linear(glb_chnls, out_chnls, bias=False),\n",
    "            t.nn.BatchNorm1d(out_chnls), t.nn.ReLU(),\n",
    "            t.nn.Linear(out_chnls, out_chnls, bias=False))\n",
    "        self.glb_feats2 = t.nn.Sequential(\n",
    "            t.nn.Linear(glb_chnls, out_chnls, bias=False), t.nn.ReLU())\n",
    "\n",
    "        # from table 9\n",
    "        self.loc_feats1 = t.nn.Sequential(\n",
    "            t.nn.Conv2d(loc_chnls, out_chnls, 1, bias=False),\n",
    "            t.nn.BatchNorm2d(out_chnls), t.nn.ReLU(),\n",
    "            t.nn.Conv2d(out_chnls, out_chnls, 1, bias=False))\n",
    "        self.loc_feats2 = t.nn.Sequential(\n",
    "            t.nn.Conv2d(loc_chnls, out_chnls, 1, bias=False), t.nn.ReLU())\n",
    "        self.layer_norm = t.nn.LayerNorm(out_chnls)\n",
    "\n",
    "        # initializ local shortcut (loc_feats2)\n",
    "        eye_mask = np.zeros((out_chnls, loc_chnls, 1, 1), dtype=np.bool)\n",
    "        for i in range(loc_chnls):\n",
    "            eye_mask[i, i, 0, 0] = 1\n",
    "        self.loc_feats2[0].weight.data.uniform_(-0.01, 0.01)\n",
    "        self.loc_feats2[0].weight.data.masked_fill_(t.tensor(eye_mask), 1.0)\n",
    "\n",
    "    def forward(self, in_loc_feats, in_glb_feats, in_loc_mask):\n",
    "        # encode local features\n",
    "        out_loc_feats = self.loc_feats1(in_loc_feats) + self.loc_feats2(\n",
    "            in_loc_feats)\n",
    "        out_loc_feats = t.permute(out_loc_feats, (0, 2, 3, 1))\n",
    "        out_loc_feats = self.layer_norm(out_loc_feats)\n",
    "        out_loc_feats = t.permute(out_loc_feats, (0, 3, 1, 2))\n",
    "\n",
    "        # encode global features\n",
    "        out_glb_feats = self.glb_feats1(in_glb_feats) + self.glb_feats2(\n",
    "            in_glb_feats)\n",
    "\n",
    "        # reshape\n",
    "        out_loc_feats = t.flatten(out_loc_feats, start_dim=-2)\n",
    "        out_glb_feats = out_glb_feats.unsqueeze(-1)\n",
    "        out_loc_mask = t.flatten(in_loc_mask, start_dim=-2)\n",
    "\n",
    "        return out_loc_feats, out_glb_feats, out_loc_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class PirorDiscriminator(BasicModule):\n",
    "\n",
    "    def __init__(self, in_chnls=128):\n",
    "        super(PirorDiscriminator, self).__init__()\n",
    "        self.model_name = 'Disc-pr'\n",
    "\n",
    "        # feature sunmmation\n",
    "        self.feats = t.nn.Sequential(t.nn.Linear(in_chnls, 512, bias=False),\n",
    "                                     t.nn.BatchNorm1d(512), t.nn.ReLU(),\n",
    "                                     t.nn.Linear(512, 512, bias=False),\n",
    "                                     t.nn.BatchNorm1d(512), t.nn.ReLU(),\n",
    "                                     t.nn.Linear(512, 1), t.nn.Sigmoid())\n",
    "\n",
    "    def forward(self, in_feats):\n",
    "        out_feats = self.feats(in_feats.view(in_feats.size(0), -1))\n",
    "\n",
    "        return out_feats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
