{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Includes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# magic command for matplotlib\n",
    "%matplotlib notebook\n",
    "\n",
    "# mass includes\n",
    "import os, sys, warnings\n",
    "import torch as t\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pickle import dump\n",
    "from umap import UMAP\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from cv2 import imread, imwrite\n",
    "\n",
    "# add paths for all sub-folders\n",
    "paths = [root for root, _, _ in os.walk('.')\\\n",
    "         if 'evals' not in root]\n",
    "for item in paths:\n",
    "    sys.path.append(item)\n",
    "\n",
    "from ipynb.fs.full.config import Config\n",
    "from ipynb.fs.full.network import *\n",
    "from ipynb.fs.full.dataLoader import *\n",
    "from ipynb.fs.full.util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define models\n",
    "opt = Config()\n",
    "net_enc = Encoder().to(opt.device)\n",
    "net_sum = Summarizer().to(opt.device)\n",
    "\n",
    "# load pre-trained weights\n",
    "net_enc.load()\n",
    "net_sum.load()\n",
    "\n",
    "# dataset for training\n",
    "test_dataset = ImageSet(opt,\n",
    "                        mode='test',\n",
    "                        norm=True,\n",
    "                        rand_trans=False,\n",
    "                        mask_out=True)\n",
    "test_loader = t.utils.data.DataLoader(test_dataset)\n",
    "\n",
    "# make result folder\n",
    "result_path = os.path.join(opt.save_path, 'results')\n",
    "if os.path.exists(result_path) is False:\n",
    "    os.makedirs(result_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# set to evaluation mode\n",
    "net_enc.eval()\n",
    "net_sum.eval()\n",
    "\n",
    "encode_list = []\n",
    "for s_idx, (sample, f_names) in enumerate(test_loader):\n",
    "    # copy to device\n",
    "    imgs = sample[:, :, :3, :, :].to(opt.device)\n",
    "    masks = sample[:, :, 3, :, :].to(opt.device).unsqueeze(2)\n",
    "\n",
    "    # reshape for batch processing\n",
    "    _, n, _, h, w = sample.size()\n",
    "    imgs = imgs.view(n, -1, h, w)\n",
    "    masks = masks.view(n, -1, h, w)\n",
    "\n",
    "    for f_idx, f_name in enumerate(f_names):\n",
    "        pred_list = []\n",
    "        iou_list = []\n",
    "        for h_idx in range(0, h - opt.crop_size, opt.win_stride):\n",
    "            for w_idx in range(0, w - opt.crop_size, opt.win_stride):\n",
    "                in_img = imgs[f_idx, :, h_idx:h_idx + opt.crop_size,\n",
    "                              w_idx:w_idx + opt.crop_size].unsqueeze(0)\n",
    "                in_mask = masks[f_idx, :, h_idx:h_idx + opt.crop_size,\n",
    "                                w_idx:w_idx + opt.crop_size].unsqueeze(0)\n",
    "\n",
    "                # extract encodings\n",
    "                with t.no_grad():\n",
    "                    pred_loc_feats, _ = net_enc(in_img, in_mask)\n",
    "                    pred_glb_feats = net_sum(pred_loc_feats)\n",
    "                    glb_feats_np = pred_glb_feats.cpu().squeeze().numpy()\n",
    "                    in_mask = in_mask.cpu().squeeze().numpy()\n",
    "\n",
    "                    # register predictions\n",
    "                    pred_list.append(glb_feats_np)\n",
    "                    iou_list.append(np.sum(in_mask) / opt.crop_size**2)\n",
    "\n",
    "        # select top n samples\n",
    "        top_n_list = np.argsort(iou_list)[-opt.top_n:]\n",
    "\n",
    "        # register samples\n",
    "        for t_idx in top_n_list:\n",
    "            encode_list.append((f_name[0], pred_list[t_idx], s_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# assemble input array\n",
    "all_data = []\n",
    "all_labels = []\n",
    "for _, sample_feats, label in encode_list:\n",
    "    all_data.append(sample_feats)\n",
    "    all_labels.append(label)\n",
    "\n",
    "# n_samples Ã— n_encodings\n",
    "all_data = np.stack(all_data, axis=0)\n",
    "\n",
    "# umap dimension reduction\n",
    "reducer = UMAP(random_state=42)\n",
    "all_embeds = reducer.fit_transform(all_data)\n",
    "\n",
    "# show distribution\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.scatter(all_embeds[:, 0], all_embeds[:, 1], c=all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit GMM cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# fit GMM and predict labels\n",
    "cluster_list = GMM(n_components=opt.data_part[1],\n",
    "                   init_params='k-means++',\n",
    "                   max_iter=1000,\n",
    "                   random_state=42).fit_predict(all_embeds)\n",
    "\n",
    "# collect all clusters\n",
    "cluster_dict = {}\n",
    "for d_idx, (f_name, _, _) in enumerate(encode_list):\n",
    "    if f_name in cluster_dict:\n",
    "        cluster_dict[f_name].append(cluster_list[d_idx])\n",
    "    else:\n",
    "        cluster_dict[f_name] = [cluster_list[d_idx]]\n",
    "\n",
    "# find dominant cluster\n",
    "for f_name in cluster_dict:\n",
    "    # read 3 channels\n",
    "    file_path = os.path.join(opt.data_path, f_name)\n",
    "    r = imread(file_path + '-actin.tif', -1)\n",
    "    b = imread(file_path + '-DNA.tif', -1)\n",
    "    g = imread(file_path + '-pH3.tif', -1)\n",
    "\n",
    "    # assemble as rgb image\n",
    "    out_img = np.stack([b, g, r], axis=-1).astype('float32')\n",
    "    out_img = (out_img - np.min(out_img)) / (np.max(out_img) - np.min(out_img))\n",
    "    out_img = (out_img * 255).astype('uint8')\n",
    "\n",
    "    dom_label = np.argmax(np.bincount(cluster_dict[f_name]))\n",
    "\n",
    "    # save image according to the label\n",
    "    file_path = os.path.join(result_path,\n",
    "                             'M%02d-F%s.png' % (dom_label, f_name))\n",
    "    imwrite(file_path, out_img)\n",
    "\n",
    "print('Classification results have been save to %s' % result_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
