{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Includes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# mass includes\n",
    "import os\n",
    "import torch as t\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pickle import load, dump\n",
    "from torch.utils.data import Dataset\n",
    "from ipynb.fs.full.util import randCrop, randHorFlip, randVerFlip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class ImageSet(Dataset):\n",
    "\n",
    "    def __init__(self, opt, mode='train', partition=[0.7, 0.3]):\n",
    "        assert mode in ['train', 'test'], print('Invalid mode: %s' % mode)\n",
    "        self.data_path = opt.data_path\n",
    "        self.crop_size = opt.crop_size\n",
    "        self.mode = mode\n",
    "\n",
    "        # list all samples\n",
    "        self.file_list = [\n",
    "            file for file in os.listdir(self.data_path) if '.tif' in file\n",
    "        ]\n",
    "        self.file_list.sort()\n",
    "\n",
    "        # load normalization params\n",
    "        param_path = os.path.join(opt.save_path, 'norm_params.pkl')\n",
    "        if os.path.exists(param_path):\n",
    "            with open(param_path, 'rb') as file:\n",
    "                data_dict = load(file)\n",
    "            self.mean = data_dict['mean']\n",
    "            self.std = data_dict['std']\n",
    "\n",
    "        else:\n",
    "            # calculate mean for each channel\n",
    "            total = [0.0, 0.0, 0.0]\n",
    "            count = [0, 0, 0]\n",
    "            for idx, f_name in enumerate(self.file_list):\n",
    "                file_path = os.path.join(self.data_path, f_name)\n",
    "                img = np.array(Image.open(file_path))\n",
    "                total[idx % 3] += np.sum(img)\n",
    "                count[idx % 3] += np.prod(img.shape)\n",
    "            self.mean = [x / y for (x, y) in zip(total, count)]\n",
    "\n",
    "            # calculate std for each channel\n",
    "            diff = [0.0, 0.0, 0.0]\n",
    "            count = [0, 0, 0]\n",
    "            for idx, f_name in enumerate(self.file_list):\n",
    "                file_path = os.path.join(self.data_path, f_name)\n",
    "                img = np.array(Image.open(file_path))\n",
    "                diff[idx % 3] += np.sum((img - self.mean[idx % 3])**2)\n",
    "                count[idx % 3] += np.prod(img.shape)\n",
    "            self.std = [np.sqrt(x / y) for (x, y) in zip(diff, count)]\n",
    "\n",
    "            # save to file\n",
    "            save_dict = {'mean': self.mean, 'std': self.std}\n",
    "            with open(param_path, 'wb') as file:\n",
    "                dump(save_dict, file)\n",
    "\n",
    "        # divide into training and testing sets\n",
    "        if mode == 'train':\n",
    "            end_idx = round(len(self.file_list) / 3 * partition[0]) * 3\n",
    "            self.file_list = self.file_list[:int(end_idx)]\n",
    "        else:\n",
    "            start_idx = round(len(self.file_list) / 3 * partition[1]) * 3\n",
    "            self.file_list = self.file_list[int(-start_idx):]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # load all three channels\n",
    "        out_img = []\n",
    "        for i in range(3):\n",
    "            f_name = self.file_list[int(index * 3 + i)]\n",
    "            file_path = os.path.join(self.data_path, f_name)\n",
    "            img = np.array(Image.open(file_path), dtype='float32')\n",
    "\n",
    "            # normalize to [-1,1]\n",
    "            out_img.append((img - self.mean[i]) / self.std[i])\n",
    "\n",
    "        # to 3D array\n",
    "        out_img = np.stack(out_img, axis=0)\n",
    "\n",
    "        # random transforms\n",
    "        out_img = randCrop(out_img, crop_size=self.crop_size)\n",
    "        out_img = randHorFlip(out_img)\n",
    "        out_img = randVerFlip(out_img)\n",
    "\n",
    "        # to pytorch tensor\n",
    "        out_img = t.tensor(out_img)\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            return out_img\n",
    "        else:\n",
    "            return out_img, f_name.split('-')[0]\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return int(len(self.file_list) / 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
